name: Deploy
inputs:
- {name: Model, type: Model}
outputs:
- {name: model, type: Model}
implementation:
  container:
    image: python:3.8-slim
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-aiplatform' 'sklearn' 'kfp==1.8.9' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef deploy(\n    Model: Input[Model],\n    model: Output[Model]\n\
      ):\n    from google.cloud import aiplatform\n    import time\n\n    TIME_STAMP\
      \ = str(int(time.time()))\n    DISPLAY_NAME = f\"blackfriday-price-prediction-{TIME_STAMP}\"\
      \n    MODEL_NAME = f\"black-friday-model-{TIME_STAMP}\"\n    ENDPOINT_NAME =\
      \ f\"black-friday-endpoint-{TIME_STAMP}\"\n    PROJECT = 'niveustraining'\n\
      \    REGION = 'us-central1'\n\n    aiplatform.init(project=PROJECT, location=REGION)\n\
      \n    endpoint = aiplatform.Endpoint.create(\n            display_name=ENDPOINT_NAME,\
      \ project=PROJECT, location=REGION\n    )\n\n    model_upload = aiplatform.Model.upload(\n\
      \        display_name=DISPLAY_NAME,\n        artifact_uri=Model.uri.replace(\"\
      model\", \"\"),\n        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\
      ,\n        serving_container_health_route=f\"/v1/models/{MODEL_NAME}\",\n  \
      \      serving_container_predict_route=f\"/v1/models/{MODEL_NAME}:predict\"\
      ,\n        serving_container_environment_variables={\n            \"MODEL_NAME\"\
      : MODEL_NAME,\n        }\n    )\n\n    model_deploy = model_upload.deploy(\n\
      \        machine_type=\"n1-standard-4\", \n        endpoint=endpoint,\n    \
      \    traffic_split={\"0\": 100},\n        deployed_model_display_name=DISPLAY_NAME,\n\
      \    )\n\n    # Save data to the output params\n    model.uri = model_deploy.resource_name\n\
      \n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - deploy
