name: Clean data
inputs:
- {name: dataset, type: Dataset}
outputs:
- {name: cleaned_data, type: Artifact}
- {name: column_transformer, type: Artifact}
- {name: label_encoder, type: Artifact}
- {name: dataset_data, type: Markdown}
implementation:
  container:
    image: python:3.8-slim
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'np' 'sklearn' 'fsspec' 'gcsfs' 'kfp==1.8.9' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def clean_data(
          dataset: Input[Dataset],
          cleaned_data: Output[Artifact],
          column_transformer: Output[Artifact],
          label_encoder: Output[Artifact],
          dataset_data: Output[Markdown]
      ):
          import json
          import numpy as np
          import pandas as pd
          from pickle import dump
          from sklearn.impute import SimpleImputer
          from sklearn.compose import ColumnTransformer
          from sklearn.preprocessing import LabelEncoder, OneHotEncoder

          df = pd.read_csv(dataset.uri)

          df.drop(['User_ID', 'Product_ID', 'Product_Category_3'], axis=1, inplace=True)
          df.Product_Category_2.fillna(method='ffill', inplace=True)
          df.dropna(subset=['Product_Category_2'], inplace=True)
          df.Product_Category_2   = df.Product_Category_2.astype(int)

          x = df.iloc[:, :-1].values
          y = df.iloc[:, -1].values

          json_data = json.dumps({"dataset":[{_: df[_].unique().tolist()}for _ in df.drop(['Purchase'], axis=1).columns.tolist()]}, indent=4)

          markdown_content = f"""
          ```json
          {json_data}
          ```
          """

          with open(dataset_data.path, 'w') as f:
              f.write(markdown_content)

          #Encode Gender column
          le = LabelEncoder()
          x[:, 0] = le.fit_transform(x[:, 0])

          # Onehot encode the Age, City_Category, Stay_In_Current_City_Years columns
          ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 3, 4])], remainder='passthrough')
          x = ct.fit_transform(x)

          # Merge the dataset to pass it to the next component
          x = pd.DataFrame(x)
          y = pd.DataFrame(y)
          data = pd.concat([x,y], axis=1)

          # Write the data to a csv file
          data.to_csv(path_or_buf=cleaned_data.path, index=False)

          # Write the column transformer object into a file
          with open(column_transformer.path, 'wb') as output_file:
              dump(ct, output_file)

          with open(label_encoder.path, 'wb') as output_file:
              dump(le, output_file)

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - clean_data
